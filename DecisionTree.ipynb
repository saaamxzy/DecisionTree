{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the attachment for a hand-drawn plot of the first three levels of the tree.\n",
    "\n",
    "Training error: 0.0\n",
    "Test Error: 0.171\n",
    "\n",
    "training error(before pruning): 0.0\n",
    "\n",
    "test error(before pruning): 0.171\n",
    "\n",
    "validation error (before pruning): 0.178.\n",
    "\n",
    "\n",
    "\n",
    "training error(after 1 pruning): 0.0205\n",
    "\n",
    "validation error (after 1 pruning): 0.163.\n",
    "\n",
    "test error(after 1 pruning): 0.157\n",
    "\n",
    "\n",
    "\n",
    "training error(after 2 pruning): 0.105\n",
    "\n",
    "validation error (after 2 pruning): 0.107.\n",
    "\n",
    "test error(after 2 pruning): 0.103\n",
    "\n",
    "\n",
    "The payment_delay_month feature is the most salient feature because if a person submitted late payment or no payment in the past it is very likely that the person would do it again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "import time\n",
    "import random\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, level):\n",
    "        self.level = level\n",
    "        self.parent = None\n",
    "        self.le_yes_child = None\n",
    "        self.gt_no_child = None\n",
    "        self.data = data\n",
    "        self.is_leaf = None\n",
    "        self.pure = None\n",
    "        self.f = None\n",
    "        self.t = None\n",
    "        \n",
    "        if self.pure == None:\n",
    "            if len(set(self.data[:,-1])) != 1:\n",
    "                self.pure = False\n",
    "                self.is_leaf = False\n",
    "            else:\n",
    "                self.pure = True\n",
    "                self.is_leaf = True\n",
    "                \n",
    "                \n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "        if len(set(self.data[:,-1])) != 1:\n",
    "            self.pure = False\n",
    "            self.is_leaf = False\n",
    "        else:\n",
    "            self.pure = True\n",
    "            self.is_leaf = True\n",
    "                \n",
    "    def majority(self):\n",
    "        labels = self.data[:,-1]\n",
    "        ones = np.count_nonzero(labels)\n",
    "        zeros = labels.shape[0] - ones\n",
    "        if ones > zeros:\n",
    "            return 1.0\n",
    "        elif ones < zeros:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return random.choice([0.0, 1.0])\n",
    "        \n",
    "    def is_pure(self):\n",
    "        return self.pure\n",
    "        \n",
    "    def set_le_yes_child(self, child):\n",
    "        self.le_yes_child = child\n",
    "        \n",
    "    def set_gt_no_child(self, child):\n",
    "        self.gt_no_child = child\n",
    "        \n",
    "    def print_node(self, outfile, level=10000, print_data = False):\n",
    "        if self.level < level:\n",
    "            if self.is_leaf:\n",
    "                outfile.write('Node level: {}, is_leaf: {}, label: {}.\\n'.format(self.level+1, self.is_leaf, self.majority()))\n",
    "            else:\n",
    "                outfile.write('Node level: {}, is_leaf: {}, rule: feature_{} <= {}.\\n'.format(self.level+1, self.is_leaf, self.f+1, self.t))\n",
    "            if print_data:\n",
    "                outfile.write('data in node has labels: {}\\n'.format(self.data[:,-1]))\n",
    "            if self.le_yes_child is not None:\n",
    "                self.le_yes_child.print_node(outfile, level, print_data)\n",
    "            if self.le_yes_child is not None:\n",
    "                self.gt_no_child.print_node(outfile, level, print_data)\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    f = open(filename, 'r')\n",
    "    ls = []\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            content = line.strip().split()\n",
    "            ls.append([float(x) for x in content])\n",
    "        \n",
    "    f.close()\n",
    "    ls = np.asarray(ls)\n",
    "    return ls\n",
    "\n",
    "\n",
    "def find_splitting_rule(node):\n",
    "    num_of_features = node.data.shape[1] - 1\n",
    "    max_IG = 0.0\n",
    "    max_t = None\n",
    "    max_f = None\n",
    "    for i in range(num_of_features):\n",
    "        feature_vals = list(set(node.data[:,i]))\n",
    "        feature_vals_sorted = sorted(feature_vals)\n",
    "        thresholds = [(feature_vals_sorted[j] + feature_vals_sorted[j+1]) / 2 for j in range(len(feature_vals_sorted)-1)]\n",
    "        X_entropy = entropy(node.data)\n",
    "        for t in thresholds:\n",
    "            X_Z_entropy = conditional_entropy(node.data, i, t)\n",
    "            IG = X_entropy - X_Z_entropy\n",
    "            if IG > max_IG:\n",
    "                max_IG = IG\n",
    "                max_f = i\n",
    "                max_t = t\n",
    "    node.is_leaf = False\n",
    "    node.f = max_f\n",
    "    node.t = max_t\n",
    "    yes_data, no_data = split_data(node.data, node.f, node.t)\n",
    "\n",
    "    \n",
    "    l_node = Node(yes_data, node.level+1)\n",
    "    r_node = Node(no_data, node.level+1)\n",
    "    l_node.parent = node\n",
    "    r_node.parent = node\n",
    "    \n",
    "    node.set_le_yes_child(l_node)\n",
    "    node.set_gt_no_child(r_node)\n",
    "    \n",
    "def split_data(data, f, t):\n",
    "    features = data[:,f]\n",
    "    yes_index = np.where(features <= t)\n",
    "    no_index = np.where(features > t)\n",
    "    yes_branch = data[yes_index]\n",
    "    no_branch = data[no_index]\n",
    "    \n",
    "    return yes_branch, no_branch\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "def entropy(data, labels = None):\n",
    "    if labels is None:\n",
    "        labels = data[:,-1]\n",
    "    total = labels.shape[0] + 0.0\n",
    "    ones = np.count_nonzero(labels) + 0.0\n",
    "    if ones == 0.0:\n",
    "        return 0.0\n",
    "    zeros = total - ones\n",
    "    if zeros == 0.0:\n",
    "        return 0.0\n",
    "    p_zero = zeros / total\n",
    "    p_one = ones / total\n",
    "    ent = -p_zero * log(p_zero) - p_one * log(p_one)\n",
    "\n",
    "    return ent\n",
    "\n",
    "def conditional_entropy(data, i, t):\n",
    "    labels = data[:,-1]\n",
    "    features = data[:,i]\n",
    "    \n",
    "    yes_branch = np.where(features <= t)\n",
    "    no_branch = np.where(features > t)\n",
    "    \n",
    "    yes_labels = labels[yes_branch]\n",
    "    no_labels = labels[no_branch]\n",
    "    \n",
    "    num_yes = yes_labels.shape[0]\n",
    "    num_no = no_labels.shape[0]\n",
    "\n",
    "    p_yes = float(num_yes) / float(num_yes + num_no)\n",
    "    p_no = float(num_no) / float(num_yes + num_no)\n",
    "\n",
    "    X_yes_entropy = entropy(data, yes_labels)\n",
    "    X_no_entropy = entropy(data, no_labels)\n",
    "    \n",
    "    rs = p_yes * X_yes_entropy + p_no * X_no_entropy\n",
    "\n",
    "    return rs\n",
    "    \n",
    "def predict(root, sample):\n",
    "    if root.is_pure():\n",
    "        return root.data[:,-1][0]\n",
    "    cur = root\n",
    "    while not cur.is_leaf:\n",
    "        f = cur.f\n",
    "        t = cur.t\n",
    "        if sample[f] <= t:\n",
    "            cur = cur.le_yes_child\n",
    "        else:\n",
    "            cur = cur.gt_no_child\n",
    "    return cur.data[:,-1][0]\n",
    "\n",
    "def evaluate(root, eval_data):\n",
    "    err_count = 0.0\n",
    "    total_count = eval_data.shape[0]\n",
    "    for each in eval_data:\n",
    "        prediction = predict(root, each)\n",
    "        if prediction != each[-1]:\n",
    "            err_count += 1.0\n",
    "    error = err_count / total_count\n",
    "    return error\n",
    "    \n",
    "def prune(root, val_data):\n",
    "    queue = []\n",
    "    queue.append(root)\n",
    "    min_error = evaluate(root, val_data)\n",
    "    while queue:\n",
    "        cur = queue.pop()\n",
    "        majority = cur.majority()\n",
    "        old_data = deepcopy(cur.data)\n",
    "        cur.set_data(np.array([[majority]]))\n",
    "        val_error = evaluate(root, val_data)\n",
    "        if val_error < min_error:\n",
    "            cur.le_yes_child = None\n",
    "            cur.gt_no_child = None\n",
    "            return val_error\n",
    "        else:\n",
    "            cur.set_data(old_data)\n",
    "            if not cur.le_yes_child is None:\n",
    "                queue.append(cur.le_yes_child)\n",
    "            if not cur.gt_no_child is None:\n",
    "                queue.append(cur.gt_no_child)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = read_file('./data/pa2train.txt')\n",
    "val_data = read_file('./data/pa2validation.txt')\n",
    "test_data = read_file('./data/pa2test.txt')\n",
    "num_of_samples = train_data.shape[0]\n",
    "num_of_features = train_data.shape[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 2.7438628673553467 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "impure_nodes = []\n",
    "root = Node(train_data, 0)\n",
    "if root.is_pure():\n",
    "    print('root is pure. No need to continue.')\n",
    "else:\n",
    "    impure_nodes.append(root)\n",
    "    \n",
    "while(impure_nodes):\n",
    "    cur = impure_nodes.pop()\n",
    "    if cur.is_pure():\n",
    "        continue\n",
    "    else:\n",
    "        find_splitting_rule(cur)\n",
    "        impure_nodes.append(cur.le_yes_child)\n",
    "        impure_nodes.append(cur.gt_no_child)\n",
    "        count += 2\n",
    "    \n",
    "end = time.time()\n",
    "total = end - start\n",
    "print('time used: {} seconds.'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error(before pruning): 0.0\n",
      "test error(before pruning): 0.171\n",
      "validation error (before pruning): 0.178.\n",
      "\n",
      "training error(after 1 pruning): 0.0205\n",
      "validation error (after 1 pruning): 0.163.\n",
      "test error(after 1 pruning): 0.157\n",
      "\n",
      "training error(after 2 pruning): 0.105\n",
      "validation error (after 2 pruning): 0.107.\n",
      "test error(after 2 pruning): 0.103\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# ***************NOTE*************** #\n",
    "#                                    #\n",
    "# Please run this only one time or   #\n",
    "# you will get wrong results. If you #\n",
    "# need to run it again please run all#\n",
    "# above blocks again before running  #\n",
    "# this block.                        #\n",
    "######################################\n",
    "\n",
    "train_error = evaluate(root, train_data)\n",
    "print('training error(before pruning): {}'.format(train_error))\n",
    "test_error = evaluate(root, test_data)\n",
    "print('test error(before pruning): {}'.format(test_error))\n",
    "val_error = evaluate(root, val_data)\n",
    "print('validation error (before pruning): {}.'.format(val_error))\n",
    "print()\n",
    "# pruning\n",
    "# round 1\n",
    "val_error = prune(root, val_data)\n",
    "train_error = evaluate(root, train_data)\n",
    "print('training error(after 1 pruning): {}'.format(train_error))\n",
    "val_error = evaluate(root, val_data)\n",
    "print('validation error (after 1 pruning): {}.'.format(val_error))\n",
    "test_error = evaluate(root, test_data)\n",
    "print('test error(after 1 pruning): {}'.format(test_error))\n",
    "print()\n",
    "# round 2\n",
    "val_error = prune(root, val_data)\n",
    "train_error = evaluate(root, train_data)\n",
    "print('training error(after 2 pruning): {}'.format(train_error))\n",
    "val_error = evaluate(root, val_data)\n",
    "print('validation error (after 2 pruning): {}.'.format(val_error))\n",
    "test_error = evaluate(root, test_data)\n",
    "print('test error(after 2 pruning): {}'.format(test_error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you want to check out the nodes in the tree, run this block\n",
    "out = open('out', 'w')\n",
    "# Currently it prints out the first 3 levels of nodes. \n",
    "# If you want to print out the whole tree, use:\n",
    "# root.print_node(out)\n",
    "root.print_node(out, level = 3)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
