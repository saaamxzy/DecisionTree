{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "import time\n",
    "import random\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, level):\n",
    "        self.level = level\n",
    "        self.parent = None\n",
    "        self.le_yes_child = None\n",
    "        self.gt_no_child = None\n",
    "        self.data = data\n",
    "        self.is_leaf = None\n",
    "        self.pure = None\n",
    "        self.f = None\n",
    "        self.t = None\n",
    "        \n",
    "        if self.pure == None:\n",
    "            if len(set(self.data[:,-1])) != 1:\n",
    "                self.pure = False\n",
    "                self.is_leaf = False\n",
    "            else:\n",
    "                self.pure = True\n",
    "                self.is_leaf = True\n",
    "                \n",
    "                \n",
    "    def set_data(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "        if len(set(self.data[:,-1])) != 1:\n",
    "            self.pure = False\n",
    "            self.is_leaf = False\n",
    "        else:\n",
    "            self.pure = True\n",
    "            self.is_leaf = True\n",
    "                \n",
    "    def majority(self):\n",
    "        labels = self.data[:,-1]\n",
    "        ones = np.count_nonzero(labels)\n",
    "        zeros = labels.shape[0] - ones\n",
    "        if ones > zeros:\n",
    "            return 1.0\n",
    "        elif ones < zeros:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return random.choice([0.0, 1.0])\n",
    "        \n",
    "    def is_pure(self):\n",
    "        return self.pure\n",
    "        \n",
    "    def set_le_yes_child(self, child):\n",
    "        self.le_yes_child = child\n",
    "        \n",
    "    def set_gt_no_child(self, child):\n",
    "        self.gt_no_child = child\n",
    "        \n",
    "    def print_node(self, outfile, level=10000, print_data = False):\n",
    "        if self.level < level:\n",
    "            if self.le_yes_child is not None:\n",
    "                self.le_yes_child.print_node(outfile, level, print_data)\n",
    "            if self.le_yes_child is not None:\n",
    "                self.gt_no_child.print_node(outfile, level, print_data)\n",
    "            outfile.write('Node level: {}, is_leaf: {}, rule: feature_{} <= {}.\\n'.format(self.level, self.is_leaf, self.f, self.t))\n",
    "            if print_data:\n",
    "                outfile.write('data in node has labels: {}\\n'.format(self.data[:,-1]))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    f = open(filename, 'r')\n",
    "    ls = []\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            content = line.strip().split()\n",
    "            ls.append([float(x) for x in content])\n",
    "        \n",
    "    f.close()\n",
    "    ls = np.asarray(ls)\n",
    "    return ls\n",
    "\n",
    "\n",
    "def find_splitting_rule(node):\n",
    "    num_of_features = node.data.shape[1] - 1\n",
    "    max_IG = 0.0\n",
    "    max_t = None\n",
    "    max_f = None\n",
    "    for i in range(num_of_features):\n",
    "        feature_vals = list(set(node.data[:,i]))\n",
    "        feature_vals_sorted = sorted(feature_vals)\n",
    "        #print(feature_vals_sorted)\n",
    "        thresholds = [(feature_vals_sorted[j] + feature_vals_sorted[j+1]) / 2 for j in range(len(feature_vals_sorted)-1)]\n",
    "        #print(thresholds)\n",
    "        X_entropy = entropy(node.data)\n",
    "        for t in thresholds:\n",
    "            X_Z_entropy = conditional_entropy(node.data, i, t)\n",
    "            IG = X_entropy - X_Z_entropy\n",
    "            if IG > max_IG:\n",
    "                max_IG = IG\n",
    "                max_f = i\n",
    "                max_t = t\n",
    "    node.is_leaf = False\n",
    "    node.f = max_f\n",
    "    node.t = max_t\n",
    "    yes_data, no_data = split_data(node.data, node.f, node.t)\n",
    "#     print('rule is: feature_{} <= {} (feature index from 0).'.format(max_f, max_t))\n",
    "#     print(yes_data.shape, no_data.shape)\n",
    "    \n",
    "    l_node = Node(yes_data, node.level+1)\n",
    "    r_node = Node(no_data, node.level+1)\n",
    "    l_node.parent = node\n",
    "    r_node.parent = node\n",
    "    \n",
    "    node.set_le_yes_child(l_node)\n",
    "    node.set_gt_no_child(r_node)\n",
    "    \n",
    "def split_data(data, f, t):\n",
    "    features = data[:,f]\n",
    "    yes_index = np.where(features <= t)\n",
    "    no_index = np.where(features > t)\n",
    "    yes_branch = data[yes_index]\n",
    "    no_branch = data[no_index]\n",
    "    \n",
    "    return yes_branch, no_branch\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "def entropy(data, labels = None):\n",
    "    if labels is None:\n",
    "        labels = data[:,-1]\n",
    "    total = labels.shape[0] + 0.0\n",
    "    ones = np.count_nonzero(labels) + 0.0\n",
    "    if ones == 0.0:\n",
    "        return 0.0\n",
    "    zeros = total - ones\n",
    "    if zeros == 0.0:\n",
    "        return 0.0\n",
    "    p_zero = zeros / total\n",
    "    p_one = ones / total\n",
    "    ent = -p_zero * log(p_zero) - p_one * log(p_one)\n",
    "\n",
    "    return ent\n",
    "\n",
    "def conditional_entropy(data, i, t):\n",
    "    labels = data[:,-1]\n",
    "    features = data[:,i]\n",
    "    yes_branch = np.where(features <= t)\n",
    "    no_branch = np.where(features > t)\n",
    "#     print(features)\n",
    "#     print(t)\n",
    "#     print(yes_branch[0].shape)\n",
    "#     print(no_branch[0].shape)\n",
    "    yes_labels = labels[yes_branch]\n",
    "    no_labels = labels[no_branch]\n",
    "    num_yes = yes_labels.shape[0]\n",
    "    num_no = no_labels.shape[0]\n",
    "#     print(num_yes)\n",
    "#     print(num_no)\n",
    "    p_yes = float(num_yes) / float(num_yes + num_no)\n",
    "    p_no = float(num_no) / float(num_yes + num_no)\n",
    "    #print(p_yes, p_no)\n",
    "    X_yes_entropy = entropy(data, yes_labels)\n",
    "    X_no_entropy = entropy(data, no_labels)\n",
    "    \n",
    "    rs = p_yes * X_yes_entropy + p_no * X_no_entropy\n",
    "#     print('conditional entropy: {}'.format(rs))\n",
    "    return rs\n",
    "\n",
    "def preorderTraversal(node):\n",
    "        res = []\n",
    "        if node:\n",
    "            print(node.level)\n",
    "            res.append(node.level)\n",
    "            res = preorderTraversal(node.le_yes_child)\n",
    "            res = preorderTraversal(node.gt_no_child)\n",
    "        return res\n",
    "    \n",
    "def predict(root, sample):\n",
    "    if root.is_pure():\n",
    "        return root.data[:,-1][0]\n",
    "    cur = root\n",
    "    while not cur.is_leaf:\n",
    "        f = cur.f\n",
    "        t = cur.t\n",
    "        if sample[f] <= t:\n",
    "            cur = cur.le_yes_child\n",
    "        else:\n",
    "            cur = cur.gt_no_child\n",
    "    return cur.data[:,-1][0]\n",
    "\n",
    "def evaluate(root, eval_data):\n",
    "    err_count = 0.0\n",
    "    total_count = eval_data.shape[0]\n",
    "    for each in eval_data:\n",
    "        prediction = predict(root, each)\n",
    "        if prediction != each[-1]:\n",
    "            err_count += 1.0\n",
    "    error = err_count / total_count\n",
    "    return error\n",
    "    \n",
    "def prune(root, val_data):\n",
    "    queue = []\n",
    "    queue.append(root)\n",
    "    #prune_count = 0\n",
    "    min_error = evaluate(root, val_data)\n",
    "    while queue:\n",
    "        cur = queue.pop()\n",
    "        majority = cur.majority()\n",
    "        old_data = deepcopy(cur.data)\n",
    "        cur.set_data(np.array([[majority]]))\n",
    "        val_error = evaluate(root, val_data)\n",
    "        if val_error < min_error:\n",
    "#             print('find a node to prune.')\n",
    "#             print('old data: {}, new data: {}'.format(old_data, cur.data))\n",
    "            cur.le_yes_child = None\n",
    "            cur.gt_no_child = None\n",
    "            return val_error\n",
    "        else:\n",
    "            cur.set_data(old_data)\n",
    "            if not cur.le_yes_child is None:\n",
    "                queue.append(cur.le_yes_child)\n",
    "            if not cur.gt_no_child is None:\n",
    "                queue.append(cur.gt_no_child)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = read_file('./data/pa2train.txt')\n",
    "num_of_samples = train_data.shape[0]\n",
    "num_of_features = train_data.shape[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 2.724031448364258 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "impure_nodes = []\n",
    "root = Node(train_data, 0)\n",
    "if root.is_pure():\n",
    "    print('root is pure. No need to continue.')\n",
    "else:\n",
    "    impure_nodes.append(root)\n",
    "    \n",
    "while(impure_nodes):\n",
    "    cur = impure_nodes.pop()\n",
    "    if cur.is_pure():\n",
    "        #print(cur.data[:,-1])\n",
    "        continue\n",
    "    else:\n",
    "        find_splitting_rule(cur)\n",
    "        impure_nodes.append(cur.le_yes_child)\n",
    "        impure_nodes.append(cur.gt_no_child)\n",
    "        count += 2\n",
    "    \n",
    "end = time.time()\n",
    "total = end - start\n",
    "print('time used: {} seconds.'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 0.0\n"
     ]
    }
   ],
   "source": [
    "train_error = evaluate(root, train_data)\n",
    "print('training error: {}'.format(train_error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before pruning the val error is: 0.178.\n",
      "after 1 pruning the val error is: 0.163.\n",
      "after 2 pruning the val error is: 0.107.\n"
     ]
    }
   ],
   "source": [
    "# pruning\n",
    "val_data = read_file('./data/pa2validation.txt')\n",
    "val_error = evaluate(root, val_data)\n",
    "print('before pruning the val error is: {}.'.format(val_error))\n",
    "val_error = prune(root, val_data)\n",
    "print('after 1 pruning the val error is: {}.'.format(val_error))\n",
    "val_error = prune(root, val_data)\n",
    "print('after 2 pruning the val error is: {}.'.format(val_error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing error: 0.103\n"
     ]
    }
   ],
   "source": [
    "test_data = read_file('./data/pa2test.txt')\n",
    "test_error = evaluate(root, test_data)\n",
    "print('testing error: {}'.format(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = open('out', 'w')\n",
    "root.print_node(out)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.]]\n"
     ]
    }
   ],
   "source": [
    "a = Node(np.array([[0.0]]), 1)\n",
    "b = Node(np.array([[1.0]]), 2)\n",
    "a.le_yes_child = b\n",
    "\n",
    "b.data = np.array([[2.0]])\n",
    "\n",
    "print(a.le_yes_child.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
