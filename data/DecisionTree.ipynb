{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data, level):\n",
    "        self.level = level\n",
    "        self.parent = None\n",
    "        self.le_yes_child = None\n",
    "        self.gt_no_child = None\n",
    "        self.data = data\n",
    "        self.is_leaf = None\n",
    "        self.pure = None\n",
    "        self.f = None\n",
    "        self.t = None\n",
    "        \n",
    "    def is_pure(self):\n",
    "        if self.pure == None:\n",
    "            if len(set(self.data[:,-1])) != 1:\n",
    "                self.pure = False\n",
    "                return False\n",
    "            else:\n",
    "                self.pure = True\n",
    "                return True\n",
    "        else:\n",
    "            return self.pure\n",
    "        \n",
    "    def set_le_yes_child(self, child):\n",
    "        self.le_yes_child = child\n",
    "        \n",
    "    def set_gt_no_child(self, child):\n",
    "        self.gt_no_child = child\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    f = open(filename, 'r')\n",
    "    ls = []\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            content = line.strip().split()\n",
    "            ls.append([float(x) for x in content])\n",
    "        \n",
    "    f.close()\n",
    "    ls = np.asarray(ls)\n",
    "    return ls\n",
    "\n",
    "\n",
    "def find_splitting_rule(node):\n",
    "    num_of_features = node.data.shape[1] - 1\n",
    "    max_IG = 0.0\n",
    "    max_t = None\n",
    "    max_f = None\n",
    "    for i in range(num_of_features):\n",
    "        feature_vals = list(set(node.data[:,i]))\n",
    "        feature_vals_sorted = sorted(feature_vals)\n",
    "        #print(feature_vals_sorted)\n",
    "        thresholds = [(feature_vals_sorted[j] + feature_vals_sorted[j+1]) / 2 for j in range(len(feature_vals_sorted)-1)]\n",
    "        #print(thresholds)\n",
    "        X_entropy = entropy(node.data)\n",
    "        for t in thresholds:\n",
    "            X_Z_entropy = conditional_entropy(node.data, i, t)\n",
    "            IG = X_entropy - X_Z_entropy\n",
    "            if IG > max_IG:\n",
    "                max_IG = IG\n",
    "                max_f = i\n",
    "                max_t = t\n",
    "    node.is_leaf = False\n",
    "    node.f = max_f\n",
    "    node.t = max_t\n",
    "    yes_data, no_data = split_data(node.data, node.f, node.t)\n",
    "#     print('rule is: feature_{} <= {} (feature index from 0).'.format(max_f, max_t))\n",
    "#     print(yes_data.shape, no_data.shape)\n",
    "    \n",
    "    node.set_le_yes_child(Node(yes_data, node.level+1))\n",
    "    node.set_gt_no_child(Node(no_data, node.level+1))\n",
    "    \n",
    "def split_data(data, f, t):\n",
    "    features = data[:,f]\n",
    "    yes_index = np.where(features <= t)\n",
    "    no_index = np.where(features > t)\n",
    "    yes_branch = data[yes_index]\n",
    "    no_branch = data[no_index]\n",
    "    \n",
    "    return yes_branch, no_branch\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "def entropy(data, labels = None):\n",
    "    if labels is None:\n",
    "        labels = data[:,-1]\n",
    "    total = labels.shape[0] + 0.0\n",
    "    zeros = np.count_nonzero(labels) + 0.0\n",
    "    if zeros == 0.0:\n",
    "        return 0.0\n",
    "    ones = total - zeros\n",
    "    if ones == 0.0:\n",
    "        return 0.0\n",
    "    p_zero = zeros / total\n",
    "    p_one = ones / total\n",
    "    ent = -p_zero * log(p_zero) - p_one * log(p_one)\n",
    "\n",
    "    return ent\n",
    "\n",
    "def conditional_entropy(data, i, t):\n",
    "    labels = data[:,-1]\n",
    "    features = data[:,i]\n",
    "    yes_branch = np.where(features <= t)\n",
    "    no_branch = np.where(features > t)\n",
    "#     print(features)\n",
    "#     print(t)\n",
    "#     print(yes_branch[0].shape)\n",
    "#     print(no_branch[0].shape)\n",
    "    yes_labels = labels[yes_branch]\n",
    "    no_labels = labels[no_branch]\n",
    "    num_yes = yes_labels.shape[0]\n",
    "    num_no = no_labels.shape[0]\n",
    "#     print(num_yes)\n",
    "#     print(num_no)\n",
    "    p_yes = float(num_yes) / float(num_yes + num_no)\n",
    "    p_no = float(num_no) / float(num_yes + num_no)\n",
    "    #print(p_yes, p_no)\n",
    "    X_yes_entropy = entropy(data, yes_labels)\n",
    "    X_no_entropy = entropy(data, no_labels)\n",
    "    \n",
    "    rs = p_yes * X_yes_entropy + p_no * X_no_entropy\n",
    "#     print('conditional entropy: {}'.format(rs))\n",
    "    return rs\n",
    "\n",
    "def preorderTraversal(node):\n",
    "        res = []\n",
    "        if node:\n",
    "            res.append(node.level)\n",
    "            res = preorderTraversal(node.le_yes_child)\n",
    "            res = preorderTraversal(node.gt_no_child)\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = read_file('pa2train.txt')\n",
    "num_of_samples = train_data.shape[0]\n",
    "num_of_features = train_data.shape[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 3.1704294681549072 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "impure_nodes = []\n",
    "root = Node(train_data, 0)\n",
    "if root.is_pure():\n",
    "    print('root is pure. No need to continue.')\n",
    "else:\n",
    "    impure_nodes.append(root)\n",
    "    \n",
    "while(impure_nodes):\n",
    "    cur = impure_nodes.pop()\n",
    "    if cur.is_pure():\n",
    "        #print(cur.data[:,-1])\n",
    "        continue\n",
    "    else:\n",
    "        find_splitting_rule(cur)\n",
    "        impure_nodes.append(cur.le_yes_child)\n",
    "        impure_nodes.append(cur.gt_no_child)\n",
    "    \n",
    "end = time.time()\n",
    "total = end - start\n",
    "print('time used: {} seconds.'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "rs = preorderTraversal(root)\n",
    "print(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
